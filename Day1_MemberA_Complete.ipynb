{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gqFGmj0L9Nn",
        "outputId": "fe805501-f43f-4f58-96f8-e67440481f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: pathway in /usr/local/lib/python3.12/dist-packages (0.27.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.12/dist-packages (from pathway) (3.13.2)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (8.3.1)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.4.1)\n",
            "Requirement already satisfied: h3>=4 in /usr/local/lib/python3.12/dist-packages (from pathway) (4.4.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.6.1)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.1.2)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (18.1.0)\n",
            "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.8.dev26)\n",
            "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (0.15.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (13.9.4)\n",
            "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (5.6.3)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.26.76 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.42.23)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.187.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (4.15.0)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.8.4)\n",
            "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from pathway) (4.0.5)\n",
            "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.0.1)\n",
            "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (0.8.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (1.39.1)\n",
            "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.4.16)\n",
            "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.0.5)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (3.6.1)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.12/dist-packages (from pathway) (2.34.0)\n",
            "Requirement already satisfied: google-cloud-bigquery~=3.29.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (3.29.0)\n",
            "Requirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.12/dist-packages (from pathway) (3.1.45)\n",
            "Requirement already satisfied: deltalake<0.18.0,>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from pathway) (0.17.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->pathway) (1.22.0)\n",
            "Requirement already satisfied: botocore<1.43.0,>=1.42.23 in /usr/local/lib/python3.12/dist-packages (from boto3<2.0.0,>=1.26.76->pathway) (1.42.23)\n",
            "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3<2.0.0,>=1.26.76->pathway) (0.16.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from deltalake<0.18.0,>=0.17.0->pathway) (0.7)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.12/dist-packages (from fs>=2.4.16->pathway) (1.4.4)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.12/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.12/dist-packages (from geopy>=2.4.0->pathway) (2.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.43->pathway) (4.0.12)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.2.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.9.0.post0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.51.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (5.29.5)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.14.3)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.71.2)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.12/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.7.3)\n",
            "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.12/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (8.1.8)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2.13.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.0.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.5.1)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2025.11.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.12/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.0.15)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->pathway) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->pathway) (2025.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (6.3.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (3.10)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (4.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (0.5.0)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (2.3.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from panel>=1.3.1->pathway) (3.0.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->pathway) (2.19.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->pathway) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->pathway) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->pathway) (3.6.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from google-resumable-media<3.0dev,>=2.0.0->google-cloud-bigquery~=3.29.0->pathway) (1.7.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.12/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.14)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "‚úÖ Libraries installed and Folders created.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install spacy pathway\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional\n",
        "\n",
        "# Create Project Folder Structure\n",
        "os.makedirs(\"data/test_novels\", exist_ok=True)\n",
        "os.makedirs(\"data/backstories\", exist_ok=True)\n",
        "os.makedirs(\"pipeline\", exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Libraries installed and Folders created.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional"
      ],
      "metadata": {
        "id": "A-tILk1aNrXJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# --- RE-CREATING TASK T5 (NOVEL 1) ---\n",
        "novel_content = \"\"\"Chapter 1: The Morning Routine\n",
        "Elena woke up to the sound of rain tapping against her apartment window in Madrid. She stretched her arms. The small studio was quiet.\n",
        "\n",
        "Chapter 2: Work and Life\n",
        "Her job at the library was demanding but rewarding. She spent the morning organizing the new history section. \"Elena, can you help with the archive?\" her manager asked.\n",
        "\n",
        "Chapter 3: Memories\n",
        "Walking home, she passed the old convent school. It brought back fleeting memories of her childhood. She preferred focusing on the independence she had built.\n",
        "\n",
        "Chapter 4: The Phone Call\n",
        "That evening, Elena met her friend Sofia. \"I know what you mean,\" Elena said casually. \"I actually called my father yesterday to ask for some money, and he wouldn't stop lecturing me.\" Sofia looked at her, confused.\n",
        "\n",
        "Chapter 5: Evening Calm\n",
        "Back home, Elena read a book until her eyes grew heavy. She drifted into a peaceful sleep.\"\"\"\n",
        "\n",
        "# Ensure the directory exists before writing\n",
        "os.makedirs(\"data/test_novels\", exist_ok=True)\n",
        "os.makedirs(\"data/backstories\", exist_ok=True)\n",
        "\n",
        "with open(\"data/test_novels/novel_001.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(novel_content)\n",
        "\n",
        "# --- RE-CREATING TASK T6 (BACKSTORY 1) ---\n",
        "backstory_data = {\n",
        "    \"story_id\": \"novel_001\",\n",
        "    \"character_name\": \"Elena\",\n",
        "    \"backstory\": \"Elena grew up as an orphan in Madrid. She never knew her parents and was raised by nuns.\"\n",
        "}\n",
        "\n",
        "with open(\"data/backstories/novel_001.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(backstory_data, f)\n",
        "\n",
        "print(\"‚úÖ Data files for T5 and T6 created in Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQU0G-YYOEL-",
        "outputId": "4fcaef4e-5f38-4639-b6f2-8ac8354059c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data files for T5 and T6 created in Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK T7: HIERARCHICAL CHUNKER CODE ---\n",
        "import spacy\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional\n",
        "\n",
        "# Load English language model (required for sentence splitting)\n",
        "# If this fails, make sure you ran the \"!python -m spacy download en_core_web_sm\" cell earlier\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    chunk_id: str\n",
        "    story_id: str\n",
        "    level: int  # 1=Chapter, 2=Scene, 3=Sentence\n",
        "    text: str\n",
        "    chapter_num: int\n",
        "    characters_mentioned: List[str] = field(default_factory=list)\n",
        "    parent_chunk_id: Optional[str] = None\n",
        "\n",
        "class HierarchicalChunker:\n",
        "    def __init__(self):\n",
        "        self.nlp = nlp\n",
        "\n",
        "    def _split_chapters(self, text):\n",
        "        \"\"\"Splits text based on 'Chapter X' headers.\"\"\"\n",
        "        pattern = re.compile(r'(Chapter\\s+\\d+|CHAPTER\\s+\\d+)', re.IGNORECASE)\n",
        "        splits = list(pattern.finditer(text))\n",
        "\n",
        "        chapters = []\n",
        "        if not splits:\n",
        "            return [(1, text)] # Fallback if no chapters found\n",
        "\n",
        "        for i, match in enumerate(splits):\n",
        "            start = match.start()\n",
        "            end = splits[i+1].start() if i+1 < len(splits) else len(text)\n",
        "            chapter_text = text[start:end].strip()\n",
        "            chapters.append((i+1, chapter_text))\n",
        "\n",
        "        return chapters\n",
        "\n",
        "    def _split_scenes(self, chapter_text):\n",
        "        \"\"\"Splits chapters by double newlines (paragraphs).\"\"\"\n",
        "        # We treat every paragraph/double-newline as a 'scene' for simplicity\n",
        "        scenes = re.split(r'\\n\\s*\\n', chapter_text)\n",
        "        return [s.strip() for s in scenes if s.strip()]\n",
        "\n",
        "    def _split_sentences(self, scene_text):\n",
        "        \"\"\"Uses Spacy AI to split sentences correctly.\"\"\"\n",
        "        doc = self.nlp(scene_text)\n",
        "        return [sent.text.strip() for sent in doc.sents]\n",
        "\n",
        "    def chunk_novel(self, story_id, full_text):\n",
        "        chunks = []\n",
        "\n",
        "        # LEVEL 1: CHAPTERS\n",
        "        chapters = self._split_chapters(full_text)\n",
        "\n",
        "        for chap_num, chap_text in chapters:\n",
        "            chap_id = f\"{story_id}_ch{chap_num}\"\n",
        "            chunks.append(Chunk(chap_id, story_id, 1, chap_text, chap_num))\n",
        "\n",
        "            # LEVEL 2: SCENES\n",
        "            scenes = self._split_scenes(chap_text)\n",
        "            for i, scene_text in enumerate(scenes):\n",
        "                scene_id = f\"{chap_id}_sc{i+1}\"\n",
        "                chunks.append(Chunk(scene_id, story_id, 2, scene_text, chap_num, parent_chunk_id=chap_id))\n",
        "\n",
        "                # LEVEL 3: SENTENCES\n",
        "                sentences = self._split_sentences(scene_text)\n",
        "                for j, sent_text in enumerate(sentences):\n",
        "                    sent_id = f\"{scene_id}_s{j+1}\"\n",
        "                    chunks.append(Chunk(sent_id, story_id, 3, sent_text, chap_num, parent_chunk_id=scene_id))\n",
        "\n",
        "        return chunks\n",
        "\n",
        "print(\"‚úÖ Hierarchical Chunker is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmyukw5oOc-T",
        "outputId": "25911816-51b0-4495-9226-79b91e8db058"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Hierarchical Chunker is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TESTING TASK T7 ---\n",
        "\n",
        "# 1. Read the novel file we created in Step 3\n",
        "with open(\"data/test_novels/novel_001.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# 2. Run the Chunker\n",
        "chunker = HierarchicalChunker()\n",
        "all_chunks = chunker.chunk_novel(\"novel_001\", text)\n",
        "\n",
        "# 3. Print Statistics\n",
        "print(f\"Total Chunks Created: {len(all_chunks)}\")\n",
        "\n",
        "# Filter by levels\n",
        "chapters = [c for c in all_chunks if c.level == 1]\n",
        "scenes = [c for c in all_chunks if c.level == 2]\n",
        "sentences = [c for c in all_chunks if c.level == 3]\n",
        "\n",
        "print(f\"Chapters: {len(chapters)} (Should be 5)\")\n",
        "print(f\"Scenes:   {len(scenes)}\")\n",
        "print(f\"Sentences:{len(sentences)}\")\n",
        "\n",
        "# 4. Verify Chapter 4 (The Contradiction)\n",
        "print(\"\\n--- Verifying Chapter 4 Content ---\")\n",
        "for c in chapters:\n",
        "    if c.chapter_num == 4:\n",
        "        print(f\"Found Chapter 4: '{c.text[:50]}...'\")\n",
        "\n",
        "if len(chapters) == 5:\n",
        "    print(\"\\n‚úÖ SUCCESS: Task T7 is Complete!\")\n",
        "else:\n",
        "    print(\"\\n‚ùå ERROR: Chunker did not find 5 chapters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbMUEM-_OhIS",
        "outputId": "3b64d138-7cd8-442a-8bf5-618a308a8281"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Chunks Created: 26\n",
            "Chapters: 5 (Should be 5)\n",
            "Scenes:   5\n",
            "Sentences:16\n",
            "\n",
            "--- Verifying Chapter 4 Content ---\n",
            "Found Chapter 4: 'Chapter 4: The Phone Call\n",
            "That evening, Elena met ...'\n",
            "\n",
            "‚úÖ SUCCESS: Task T7 is Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: SETUP OLLAMA IN COLAB ---\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "# 1. Install Ollama\n",
        "print(\"‚¨áÔ∏è Installing Ollama...\")\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# 2. Start Ollama Server in the Background\n",
        "print(\"‚è≥ Starting Ollama Server...\")\n",
        "# We run it as a subprocess so it doesn't block the notebook\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "time.sleep(10)  # Give it time to boot up\n",
        "\n",
        "# 3. Pull the Model (The Brain)\n",
        "# We use 'mistral' (good balance) or 'phi3' (if you want it faster)\n",
        "print(\"üß† Downloading the Model (Mistral)... this takes ~2 mins...\")\n",
        "!ollama pull mistral\n",
        "\n",
        "print(\"\\n‚úÖ OLLAMA IS READY! It is running in the background.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DDf5GbgQlbF",
        "outputId": "6af15697-3623-4898-c44e-dd5142aa9aa2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Installing Ollama...\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "‚è≥ Starting Ollama Server...\n",
            "üß† Downloading the Model (Mistral)... this takes ~2 mins...\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\n",
            "‚úÖ OLLAMA IS READY! It is running in the background.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: NARRATIVE EXTRACTOR (OLLAMA VERSION) ---\n",
        "import requests\n",
        "import json\n",
        "\n",
        "class NarrativeExtractor:\n",
        "    def __init__(self):\n",
        "        # We connect to the Ollama running inside this Colab instance\n",
        "        self.model = \"mistral\"\n",
        "        self.api_url = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "        self.system_prompt = \"\"\"\n",
        "        You are an expert literary analyst. Analyze the text for character: \"{character}\".\n",
        "        Extract structured data strictly following these JSON schemas.\n",
        "\n",
        "        OUTPUT FORMAT:\n",
        "        {\n",
        "          \"events\": [\n",
        "            {\n",
        "              \"description\": \"What happened\",\n",
        "              \"event_type\": \"action|dialogue|thought|memory\",\n",
        "              \"time_reference\": \"childhood|current|etc\",\n",
        "              \"is_flashback\": boolean\n",
        "            }\n",
        "          ],\n",
        "          \"attributes\": [\n",
        "            {\n",
        "              \"attr_name\": \"Specific name (e.g., eye_color, birthplace)\",\n",
        "              \"attr_value\": \"Extracted value\",\n",
        "              \"confidence\": \"explicit|implied\"\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "        RULES:\n",
        "        1. Only extract info relevant to \"{character}\".\n",
        "        2. If no data is found, return empty lists [].\n",
        "        3. RESPOND ONLY IN JSON. NO MARKDOWN.\n",
        "        \"\"\"\n",
        "\n",
        "    def extract(self, chunk_text, character_name):\n",
        "        \"\"\"Sends text to the internal Ollama server.\"\"\"\n",
        "        # Prepare Prompt\n",
        "        full_prompt = self.system_prompt.replace(\"{character}\", character_name)\n",
        "        full_prompt += f\"\\n\\nTEXT TO ANALYZE:\\n{chunk_text}\"\n",
        "\n",
        "        # Payload\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"prompt\": full_prompt,\n",
        "            \"stream\": False,\n",
        "            \"format\": \"json\",\n",
        "            \"options\": {\"temperature\": 0.1}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Send to localhost (Colab's internal network)\n",
        "            response = requests.post(self.api_url, json=payload)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse\n",
        "            result_json = response.json()\n",
        "            return json.loads(result_json['response'])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting with Ollama: {e}\")\n",
        "            return {\"events\": [], \"attributes\": []}\n",
        "\n",
        "print(\"‚úÖ Narrative Extractor (Ollama) is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxt_DyGbRuDG",
        "outputId": "6cad9465-1ddc-4583-8358-a176f9557fc6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Narrative Extractor (Ollama) is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: TESTING OLLAMA ---\n",
        "\n",
        "print(\"1. Initializing Extractor...\")\n",
        "extractor = NarrativeExtractor()\n",
        "\n",
        "# Retrieve Chapter 4 text from the Chunker (Task T7)\n",
        "# (This assumes you ran the Chunker code earlier)\n",
        "try:\n",
        "    chapter_4_text = next(c.text for c in all_chunks if c.chapter_num == 4 and c.level == 1)\n",
        "\n",
        "    print(f\"2. Sending Chapter 4 to Ollama...\")\n",
        "    print(\"   (This takes 10-20 seconds on CPU - Please wait)...\")\n",
        "\n",
        "    # Run Extraction\n",
        "    result = extractor.extract(chapter_4_text, \"Elena\")\n",
        "\n",
        "    # Print Result\n",
        "    print(\"\\n--- OLLAMA ANALYSIS RESULT ---\")\n",
        "    print(json.dumps(result, indent=2))\n",
        "\n",
        "    # Check Success\n",
        "    events = result.get(\"events\", [])\n",
        "    found_father = any(\"father\" in str(e).lower() for e in events)\n",
        "\n",
        "    if found_father:\n",
        "        print(\"\\n‚úÖ SUCCESS: Ollama detected the father!\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è CHECK output. If empty, try running the cell again.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"‚ö†Ô∏è Error: 'all_chunks' is missing. Please scroll up and run the 'Task T7' (Chunker) cell first!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FByXPMUmR4tW",
        "outputId": "1718114f-51ca-4a3b-9e98-22addad88ed2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Initializing Extractor...\n",
            "2. Sending Chapter 4 to Ollama...\n",
            "   (This takes 10-20 seconds on CPU - Please wait)...\n",
            "\n",
            "--- OLLAMA ANALYSIS RESULT ---\n",
            "{\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"description\": \"Elena met her friend Sofia\",\n",
            "      \"event_type\": \"dialogue\",\n",
            "      \"time_reference\": \"current\",\n",
            "      \"is_flashback\": false\n",
            "    },\n",
            "    {\n",
            "      \"description\": \"Elena called her father for money\",\n",
            "      \"event_type\": \"action\",\n",
            "      \"time_reference\": \"recent (yesterday)\",\n",
            "      \"is_flashback\": false\n",
            "    },\n",
            "    {\n",
            "      \"description\": \"Elena's father lectured her\",\n",
            "      \"event_type\": \"dialogue\",\n",
            "      \"time_reference\": \"recent (yesterday)\",\n",
            "      \"is_flashback\": false\n",
            "    }\n",
            "  ],\n",
            "  \"attributes\": [\n",
            "    {\n",
            "      \"attr_name\": \"friend\",\n",
            "      \"attr_value\": \"Sofia\",\n",
            "      \"confidence\": \"explicit\"\n",
            "    },\n",
            "    {\n",
            "      \"attr_name\": \"father\",\n",
            "      \"attr_value\": \"\",\n",
            "      \"confidence\": \"implied\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "‚úÖ SUCCESS: Ollama detected the father!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- COMPLETING TASKS T5 & T6 (MISSING FILES) ---\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Ensure folders exist\n",
        "os.makedirs(\"data/test_novels\", exist_ok=True)\n",
        "os.makedirs(\"data/backstories\", exist_ok=True)\n",
        "\n",
        "# ==========================================\n",
        "# 1. CREATE NOVEL 2 (Subtle Contradiction)\n",
        "# ==========================================\n",
        "novel_002_content = \"\"\"Chapter 1: The Move\n",
        "James looked at the boxes stacked in his living room. At age 25, he was finally moving out of his parents' house in Seattle. He had lived here his entire life, never venturing further than the state border.\n",
        "\n",
        "Chapter 2: The New Job\n",
        "His new job in Portland was exciting. He spent the first few weeks learning the ropes. He missed his mom's cooking but enjoyed the freedom.\n",
        "\n",
        "Chapter 3: Old Photos\n",
        "One evening, he was showing his girlfriend, Maya, some old photo albums. \"Look at this one,\" James said, pointing to a picture of a boy eating a croissant. \"That was me in Paris when I was ten. The Eiffel Tower was huge!\" Maya smiled, not realizing the inconsistency.\n",
        "\n",
        "Chapter 4: The Routine\n",
        "Months passed. James settled into a routine of work, gym, and sleep.\n",
        "\n",
        "Chapter 5: Reflection\n",
        "He felt he had grown up. The small town boy was now a city man.\"\"\"\n",
        "\n",
        "with open(\"data/test_novels/novel_002.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(novel_002_content)\n",
        "\n",
        "backstory_002 = {\n",
        "    \"story_id\": \"novel_002\",\n",
        "    \"character_name\": \"James\",\n",
        "    \"backstory\": \"James is a 25-year-old software engineer. He was born and raised in Seattle. A key fact about him is that he has never traveled outside of the United States.\"\n",
        "}\n",
        "with open(\"data/backstories/novel_002.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(backstory_002, f, indent=2)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2. CREATE NOVEL 3 (Consistent)\n",
        "# ==========================================\n",
        "novel_003_content = \"\"\"Chapter 1: The Detective\n",
        "Sarah polished her badge. She had been a detective for ten years in London. She was known for her sharp eye and dedication.\n",
        "\n",
        "Chapter 2: The Case\n",
        "A new case landed on her desk. A missing painting. Sarah visited the museum immediately. She interviewed the guard, who looked nervous.\n",
        "\n",
        "Chapter 3: The Clue\n",
        "She found a glove near the exit. It matched the description of the suspect. Sarah called her partner. \"We have a lead,\" she said efficiently.\n",
        "\n",
        "Chapter 4: The Chase\n",
        "They tracked the suspect to a warehouse. Sarah remembered her training at the academy. She flanked the left side while her partner took the right.\n",
        "\n",
        "Chapter 5: Justice\n",
        "They caught the thief. The painting was returned. Sarah went home to her cat, Mittens, satisfied with a job well done.\"\"\"\n",
        "\n",
        "with open(\"data/test_novels/novel_003.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(novel_003_content)\n",
        "\n",
        "backstory_003 = {\n",
        "    \"story_id\": \"novel_003\",\n",
        "    \"character_name\": \"Sarah\",\n",
        "    \"backstory\": \"Sarah is a dedicated detective in London with 10 years of experience. She lives alone with her cat, Mittens. She is known for her professionalism.\"\n",
        "}\n",
        "with open(\"data/backstories/novel_003.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(backstory_003, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ T5 & T6 COMPLETE: All 3 novels and backstories created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq_2gzYUVbHn",
        "outputId": "959a5373-fbb7-429e-bbd3-1fc6dd40d791"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T5 & T6 COMPLETE: All 3 novels and backstories created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK T8: CHARACTER-AWARE CHUNKER ---\n",
        "import spacy\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional\n",
        "\n",
        "# Load Spacy Model (Required for NER and Sentence Splitting)\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading Spacy model...\")\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    chunk_id: str\n",
        "    story_id: str\n",
        "    level: int  # 1=Chapter, 2=Scene, 3=Sentence\n",
        "    text: str\n",
        "    chapter_num: int\n",
        "    # NEW FIELDS FOR T8\n",
        "    characters_mentioned: List[str] = field(default_factory=list)\n",
        "    has_target_character: bool = False\n",
        "    parent_chunk_id: Optional[str] = None\n",
        "\n",
        "class HierarchicalChunker:\n",
        "    def __init__(self):\n",
        "        self.nlp = nlp\n",
        "\n",
        "    # T8 STEP 2: Build Aliases\n",
        "    def _build_character_aliases(self, name: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Input: \"Elena Martinez\"\n",
        "        Output: [\"elena\", \"martinez\", \"elena martinez\", \"ms. martinez\"]\n",
        "        \"\"\"\n",
        "        name = name.lower()\n",
        "        parts = name.split()\n",
        "\n",
        "        aliases = {name} # Set prevents duplicates\n",
        "        aliases.update(parts)\n",
        "\n",
        "        if len(parts) > 1:\n",
        "            aliases.add(f\"ms. {parts[-1]}\")\n",
        "            aliases.add(f\"mr. {parts[-1]}\")\n",
        "\n",
        "        return list(aliases)\n",
        "\n",
        "    # T8 STEP 3: Check Target Character\n",
        "    def _has_target_character(self, text: str, aliases: List[str]) -> bool:\n",
        "        \"\"\"Returns True if any alias is found in the text.\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        for alias in aliases:\n",
        "            # We add spaces to avoid partial matches (e.g. \"cat\" inside \"catch\")\n",
        "            # But for simplicity in hackathon, simple substring check is often okay\n",
        "            if alias in text_lower:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # T8 STEP 4: Extract All Characters (NER)\n",
        "    def _extract_all_characters(self, text: str) -> List[str]:\n",
        "        \"\"\"Uses Spacy to find PERSON entities.\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        # Return unique list of people found\n",
        "        return list(set([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]))\n",
        "\n",
        "    # (Previous helper methods from T7)\n",
        "    def _split_chapters(self, text):\n",
        "        pattern = re.compile(r'(Chapter\\s+\\d+|CHAPTER\\s+\\d+)', re.IGNORECASE)\n",
        "        splits = list(pattern.finditer(text))\n",
        "        if not splits: return [(1, text)]\n",
        "        chapters = []\n",
        "        for i, match in enumerate(splits):\n",
        "            start = match.start()\n",
        "            end = splits[i+1].start() if i+1 < len(splits) else len(text)\n",
        "            chapters.append((i+1, text[start:end].strip()))\n",
        "        return chapters\n",
        "\n",
        "    def _split_scenes(self, text):\n",
        "        return [s.strip() for s in re.split(r'\\n\\s*\\n', text) if s.strip()]\n",
        "\n",
        "    def _split_sentences(self, text):\n",
        "        return [sent.text.strip() for sent in self.nlp(text).sents]\n",
        "\n",
        "    # T8 STEP 5: Modify chunk_novel main method\n",
        "    def chunk_novel(self, story_id, full_text, target_character_name):\n",
        "        chunks = []\n",
        "\n",
        "        # Generate Aliases for the specific character\n",
        "        aliases = self._build_character_aliases(target_character_name)\n",
        "\n",
        "        # Level 1: Chapters\n",
        "        chapters = self._split_chapters(full_text)\n",
        "\n",
        "        for chap_num, chap_text in chapters:\n",
        "            chap_id = f\"{story_id}_ch{chap_num}\"\n",
        "\n",
        "            # Create Chunk Object\n",
        "            c = Chunk(chap_id, story_id, 1, chap_text, chap_num)\n",
        "\n",
        "            # --- APPLY T8 LOGIC ---\n",
        "            c.characters_mentioned = self._extract_all_characters(chap_text)\n",
        "            c.has_target_character = self._has_target_character(chap_text, aliases)\n",
        "            chunks.append(c)\n",
        "\n",
        "            # Level 2: Scenes\n",
        "            scenes = self._split_scenes(chap_text)\n",
        "            for i, scene_text in enumerate(scenes):\n",
        "                scene_id = f\"{chap_id}_sc{i+1}\"\n",
        "                s_chunk = Chunk(scene_id, story_id, 2, scene_text, chap_num, parent_chunk_id=chap_id)\n",
        "\n",
        "                # --- APPLY T8 LOGIC ---\n",
        "                s_chunk.characters_mentioned = self._extract_all_characters(scene_text)\n",
        "                s_chunk.has_target_character = self._has_target_character(scene_text, aliases)\n",
        "                chunks.append(s_chunk)\n",
        "\n",
        "                # Level 3: Sentences (Only if scene has target character)\n",
        "                if s_chunk.has_target_character:\n",
        "                    sentences = self._split_sentences(scene_text)\n",
        "                    for j, sent_text in enumerate(sentences):\n",
        "                        sent_id = f\"{scene_id}_s{j+1}\"\n",
        "                        sent_chunk = Chunk(sent_id, story_id, 3, sent_text, chap_num, parent_chunk_id=scene_id)\n",
        "\n",
        "                        # --- APPLY T8 LOGIC ---\n",
        "                        sent_chunk.has_target_character = self._has_target_character(sent_text, aliases)\n",
        "                        # Only run NER on sentence if needed (optimization)\n",
        "                        if sent_chunk.has_target_character:\n",
        "                            chunks.append(sent_chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "print(\"‚úÖ Task T8: Character-Aware Chunker Code Implemented.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Wt5AsfWNio",
        "outputId": "997e838d-82fa-4447-c509-78f2380ad29d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Task T8: Character-Aware Chunker Code Implemented.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VERIFY TASK T8 ---\n",
        "with open(\"data/test_novels/novel_001.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "chunker = HierarchicalChunker()\n",
        "# We tell it to look for \"Elena\"\n",
        "chunks = chunker.chunk_novel(\"novel_001\", text, \"Elena\")\n",
        "\n",
        "print(f\"Total Chunks Generated: {len(chunks)}\")\n",
        "\n",
        "# Check specifically for Chapter 4 (The Contradiction)\n",
        "found_elena_ch4 = False\n",
        "for c in chunks:\n",
        "    if c.level == 1 and c.chapter_num == 4:\n",
        "        print(f\"\\nChapter 4 Analysis:\")\n",
        "        print(f\"Has Target Character? {c.has_target_character}\")\n",
        "        print(f\"People found: {c.characters_mentioned}\")\n",
        "        if c.has_target_character:\n",
        "            found_elena_ch4 = True\n",
        "\n",
        "if found_elena_ch4:\n",
        "    print(\"\\n‚úÖ SUCCESS: T8 is working. Elena was detected in the target chapter.\")\n",
        "else:\n",
        "    print(\"\\n‚ùå FAIL: Elena was not detected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tofMljsTWU3x",
        "outputId": "76ee1dc7-deb6-4d4b-de48-3c70db4f8bb6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Chunks Generated: 15\n",
            "\n",
            "Chapter 4 Analysis:\n",
            "Has Target Character? True\n",
            "People found: ['Sofia']\n",
            "\n",
            "‚úÖ SUCCESS: T8 is working. Elena was detected in the target chapter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK T9 FIXED: PATHWAY DAG WITH PYTHON FUNCTIONS ---\n",
        "import pathway as pw\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- HELPER FUNCTIONS (The \"Safe\" Way) ---\n",
        "# We define simple Python functions to handle the data conversion\n",
        "# avoiding the complex Pathway .dt syntax that caused the error.\n",
        "\n",
        "@pw.udf\n",
        "def decode_utf8(data: bytes) -> str:\n",
        "    \"\"\"Safely converts binary file data to a string.\"\"\"\n",
        "    return data.decode('utf-8')\n",
        "\n",
        "@pw.udf\n",
        "def extract_story_id(path: str) -> str:\n",
        "    \"\"\"Extracts 'novel_001' from 'data/test_novels/novel_001.txt'\"\"\"\n",
        "    filename = os.path.basename(path)\n",
        "    # Remove extensions commonly used\n",
        "    return filename.replace(\".txt\", \"\").replace(\".json\", \"\")\n",
        "\n",
        "@pw.udf\n",
        "def parse_json(json_str: str) -> dict:\n",
        "    \"\"\"Parses JSON string safely.\"\"\"\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "@pw.udf\n",
        "def apply_chunker(story_id: str, text: str, character: str) -> str:\n",
        "    \"\"\"Runs the T8 Chunker logic.\"\"\"\n",
        "    c = HierarchicalChunker() # Uses the class we defined in T8\n",
        "    chunk_objs = c.chunk_novel(story_id, text, character)\n",
        "    # Convert to JSON string for the table\n",
        "    return json.dumps([vars(ch) for ch in chunk_objs])\n",
        "\n",
        "\n",
        "# --- THE PIPELINE CLASS ---\n",
        "class VeritasDAG:\n",
        "    def build_pipeline(self):\n",
        "        # STAGE A: Read Novels\n",
        "        novels = pw.io.fs.read(\n",
        "            \"./data/test_novels/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "\n",
        "        # FIX: Use UDFs instead of .dt accessors\n",
        "        novels_table = novels.select(\n",
        "            text=decode_utf8(pw.this.data),\n",
        "            story_id=extract_story_id(pw.this._metadata.path)\n",
        "        )\n",
        "\n",
        "        # STAGE B: Read Backstories\n",
        "        backstories = pw.io.fs.read(\n",
        "            \"./data/backstories/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "\n",
        "        # FIX: Use UDFs for decoding and ID extraction\n",
        "        backstories_table = backstories.select(\n",
        "            json_str=decode_utf8(pw.this.data),\n",
        "            story_id=extract_story_id(pw.this._metadata.path)\n",
        "        )\n",
        "\n",
        "        # STAGE E: Parse JSON content\n",
        "        backstories_parsed = backstories_table.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            meta=parse_json(pw.this.json_str)\n",
        "        ).select(\n",
        "            story_id=pw.this.story_id,\n",
        "            character_name=pw.this.meta[\"character_name\"]\n",
        "        )\n",
        "\n",
        "        # STAGE D: Join Novels with Backstories\n",
        "        joined_data = novels_table.join(\n",
        "            backstories_parsed,\n",
        "            pw.left.story_id == pw.right.story_id\n",
        "        ).select(\n",
        "            pw.left.story_id,\n",
        "            pw.left.text,\n",
        "            pw.right.character_name\n",
        "        )\n",
        "\n",
        "        # STAGE F: Apply Chunker\n",
        "        result_table = joined_data.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            chunk_json=apply_chunker(pw.this.story_id, pw.this.text, pw.this.character_name)\n",
        "        )\n",
        "\n",
        "        return result_table\n",
        "\n",
        "    def run(self):\n",
        "        pipeline = self.build_pipeline()\n",
        "        pw.debug.compute_and_print(pipeline)\n",
        "\n",
        "print(\"‚úÖ T9 Fixed: VeritasDAG Class updated with safe UDFs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO3V1Pb_Wa9U",
        "outputId": "b3f7c410-45d3-4d6a-e0b5-ed26fee9fa38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T9 Fixed: VeritasDAG Class updated with safe UDFs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VERIFY TASK T9 (FIXED) ---\n",
        "print(\"Running Pathway Pipeline on all test novels...\")\n",
        "dag = VeritasDAG()\n",
        "dag.run()\n",
        "\n",
        "print(\"\\n---------------------------------------------------\")\n",
        "print(\"‚úÖ SUCCESS CHECK:\")\n",
        "print(\"If you see a table above with columns 'story_id' and 'chunk_json', you are DONE with T9!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_oL1N72KWir3",
        "outputId": "8a8b7b00-13ff-4c61-e188-53063b7fc92f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Pathway Pipeline on all test novels...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ColumnReference' object has no attribute 'path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3271723804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Pathway Pipeline on all test novels...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVeritasDAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n---------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2933857730.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_and_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2933857730.py\u001b[0m in \u001b[0;36mbuild_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         novels_table = novels.select(\n\u001b[1;32m     52\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_utf8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mstory_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_story_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ColumnReference' object has no attribute 'path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK T9 FINAL FIX: ROBUST METADATA HANDLING ---\n",
        "import pathway as pw\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- SAFE HELPER FUNCTIONS (UDFs) ---\n",
        "\n",
        "@pw.udf\n",
        "def decode_utf8(data: bytes) -> str:\n",
        "    \"\"\"Safely converts binary file data to a string.\"\"\"\n",
        "    try:\n",
        "        return data.decode('utf-8')\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "@pw.udf\n",
        "def extract_story_id(metadata: dict) -> str:\n",
        "    \"\"\"\n",
        "    Receives the entire metadata dictionary and extracts the filename.\n",
        "    Safe against Pathway version changes.\n",
        "    \"\"\"\n",
        "    # The 'path' is stored inside this dictionary\n",
        "    full_path = metadata.get('path', '')\n",
        "    filename = os.path.basename(full_path)\n",
        "    # Remove extensions\n",
        "    return filename.replace(\".txt\", \"\").replace(\".json\", \"\")\n",
        "\n",
        "@pw.udf\n",
        "def parse_json(json_str: str) -> dict:\n",
        "    \"\"\"Parses JSON string safely.\"\"\"\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "@pw.udf\n",
        "def apply_chunker(story_id: str, text: str, character: str) -> str:\n",
        "    \"\"\"Runs the T8 Chunker logic.\"\"\"\n",
        "    if not text or not character:\n",
        "        return \"[]\"\n",
        "\n",
        "    # Initialize Chunker\n",
        "    c = HierarchicalChunker()\n",
        "    chunk_objs = c.chunk_novel(story_id, text, character)\n",
        "\n",
        "    # Convert to JSON string\n",
        "    return json.dumps([vars(ch) for ch in chunk_objs])\n",
        "\n",
        "\n",
        "# --- THE PIPELINE CLASS ---\n",
        "class VeritasDAG:\n",
        "    def build_pipeline(self):\n",
        "        # STAGE A: Read Novels\n",
        "        novels = pw.io.fs.read(\n",
        "            \"./data/test_novels/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "\n",
        "        # FIX 2: Pass the WHOLE _metadata object to the UDF\n",
        "        novels_table = novels.select(\n",
        "            text=decode_utf8(pw.this.data),\n",
        "            story_id=extract_story_id(pw.this._metadata)\n",
        "        )\n",
        "\n",
        "        # STAGE B: Read Backstories\n",
        "        backstories = pw.io.fs.read(\n",
        "            \"./data/backstories/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "\n",
        "        # FIX 2: Pass the WHOLE _metadata object here too\n",
        "        backstories_table = backstories.select(\n",
        "            json_str=decode_utf8(pw.this.data),\n",
        "            story_id=extract_story_id(pw.this._metadata)\n",
        "        )\n",
        "\n",
        "        # STAGE C: Parse JSON content\n",
        "        backstories_parsed = backstories_table.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            meta=parse_json(pw.this.json_str)\n",
        "        ).select(\n",
        "            story_id=pw.this.story_id,\n",
        "            character_name=pw.this.meta[\"character_name\"]\n",
        "        )\n",
        "\n",
        "        # STAGE D: Join Novels with Backstories\n",
        "        joined_data = novels_table.join(\n",
        "            backstories_parsed,\n",
        "            pw.left.story_id == pw.right.story_id\n",
        "        ).select(\n",
        "            pw.left.story_id,\n",
        "            pw.left.text,\n",
        "            pw.right.character_name\n",
        "        )\n",
        "\n",
        "        # STAGE F: Apply Chunker\n",
        "        result_table = joined_data.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            chunk_json=apply_chunker(pw.this.story_id, pw.this.text, pw.this.character_name)\n",
        "        )\n",
        "\n",
        "        return result_table\n",
        "\n",
        "    def run(self):\n",
        "        pipeline = self.build_pipeline()\n",
        "        pw.debug.compute_and_print(pipeline)\n",
        "\n",
        "print(\"‚úÖ T9 Final Fix: VeritasDAG updated to handle metadata safely.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1uzwlk_Zx1l",
        "outputId": "f66c2330-ccb6-4069-bff4-6543607bb6e5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T9 Final Fix: VeritasDAG updated to handle metadata safely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VERIFY TASK T9 (FINAL) ---\n",
        "print(\"Running Pathway Pipeline on all test novels...\")\n",
        "dag = VeritasDAG()\n",
        "dag.run()\n",
        "\n",
        "print(\"\\n---------------------------------------------------\")\n",
        "print(\"‚úÖ CHECKLIST:\")\n",
        "print(\"If you see a table above with columns 'story_id' and 'chunk_json', you are DONE!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "QBWSJ8v8Z07B",
        "outputId": "e8bfa2ed-a9c2-48c5-ad9b-ab79d06d9675"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Pathway Pipeline on all test novels...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(./data/test_novels/): Closing the data source\n",
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(./data/backstories/): Closing the data source\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Json' object has no attribute 'get'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-404362961.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Pathway Pipeline on all test novels...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVeritasDAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n---------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3314341651.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_and_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ T9 Final Fix: VeritasDAG updated to handle metadata safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/internals/runtime_type_check.py\u001b[0m in \u001b[0;36mwith_type_validation\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \"\"\"\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeartypeCallHintParamViolation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<@beartype(pathway.debug.compute_and_print) at 0x7a4fc32b6ca0>\u001b[0m in \u001b[0;36mcompute_and_print\u001b[0;34m(__beartype_func, __beartype_conf, __beartype_get_violation, __beartype_object_820835056, __beartype_object_134482826855360, __beartype_object_10572672, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/internals/trace.py\u001b[0m in \u001b[0;36m_pathway_trace_marker\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0m_reraise_with_user_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pathway_trace_marker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/internals/trace.py\u001b[0m in \u001b[0;36m_reraise_with_user_frame\u001b[0;34m(e, trace)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_pathway_trace_note\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/debug/__init__.py\u001b[0m in \u001b[0;36mcompute_and_print\u001b[0;34m(include_id, short_pointers, n_rows, *tables, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mn_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrows\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0mwhole\u001b[0m \u001b[0mtable\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mprinted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m     _compute_and_print_internal(\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0msquash_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/debug/__init__.py\u001b[0m in \u001b[0;36m_compute_and_print_internal\u001b[0;34m(squash_updates, include_id, short_pointers, n_rows, _stacklevel, *tables, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m ) -> None:\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mcaptured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_pathway_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/internals/runtime_type_check.py\u001b[0m in \u001b[0;36mwith_type_validation\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \"\"\"\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeartypeCallHintParamViolation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<@beartype(pathway.debug._compute_tables) at 0x7a4fede47ce0>\u001b[0m in \u001b[0;36m_compute_tables\u001b[0;34m(__beartype_func, __beartype_conf, __beartype_get_violation, __beartype_object_820835056, __beartype_object_848920576, __beartype_getrandbits, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/debug/__init__.py\u001b[0m in \u001b[0;36m_compute_tables\u001b[0;34m(_stacklevel, *tables, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m ) -> list[api.CapturedStream]:\n\u001b[0;32m---> 50\u001b[0;31m     captured = GraphRunner(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mparse_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/internals/graph_runner/__init__.py\u001b[0m in \u001b[0;36mrun_tables\u001b[0;34m(self, after_build, *tables)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ) -> list[api.CapturedStream]:\n\u001b[1;32m    102\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_shake_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter_build\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mafter_build\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     def run_all(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pathway/internals/graph_runner/__init__.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, nodes, output_tables, after_build, run_all)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             ),\n\u001b[1;32m    233\u001b[0m                         )\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOtherWorkerError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpathway_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_other_worker_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3314341651.py\u001b[0m in \u001b[0;36mextract_story_id\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# The 'path' is stored inside this dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Remove extensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Json' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK T9 FINAL FIX (PROTOCOL 3) ---\n",
        "import pathway as pw\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- SAFE HELPER FUNCTIONS (UDFs) ---\n",
        "\n",
        "@pw.udf\n",
        "def decode_utf8(data: bytes) -> str:\n",
        "    \"\"\"Safely converts binary file data to a string.\"\"\"\n",
        "    try:\n",
        "        return data.decode('utf-8')\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "@pw.udf\n",
        "def extract_id_from_path(path_val) -> str:\n",
        "    \"\"\"\n",
        "    Receives the path (which might be a wrapper object) and cleans it.\n",
        "    \"\"\"\n",
        "    # Force convert to string to handle any Pathway wrapper types safely\n",
        "    full_path = str(path_val)\n",
        "    filename = os.path.basename(full_path)\n",
        "    return filename.replace(\".txt\", \"\").replace(\".json\", \"\")\n",
        "\n",
        "@pw.udf\n",
        "def parse_json(json_str: str) -> dict:\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "@pw.udf\n",
        "def apply_chunker(story_id: str, text: str, character: str) -> str:\n",
        "    if not text or not character:\n",
        "        return \"[]\"\n",
        "\n",
        "    # We need to re-instantiate the chunker inside the UDF context\n",
        "    # (Ensure HierarchicalChunker class cell was run previously!)\n",
        "    try:\n",
        "        c = HierarchicalChunker()\n",
        "        chunk_objs = c.chunk_novel(story_id, text, character)\n",
        "        return json.dumps([vars(ch) for ch in chunk_objs])\n",
        "    except Exception as e:\n",
        "        return json.dumps([{\"error\": str(e)}])\n",
        "\n",
        "\n",
        "# --- THE PIPELINE CLASS ---\n",
        "class VeritasDAG:\n",
        "    def build_pipeline(self):\n",
        "        # STAGE A: Read Novels\n",
        "        novels = pw.io.fs.read(\n",
        "            \"./data/test_novels/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "\n",
        "        # FIX: Use [\"path\"] bracket access instead of .path or .get()\n",
        "        novels_table = novels.select(\n",
        "            text=decode_utf8(pw.this.data),\n",
        "            story_id=extract_id_from_path(pw.this._metadata[\"path\"])\n",
        "        )\n",
        "\n",
        "        # STAGE B: Read Backstories\n",
        "        backstories = pw.io.fs.read(\n",
        "            \"./data/backstories/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "\n",
        "        # FIX: Use [\"path\"] bracket access here too\n",
        "        backstories_table = backstories.select(\n",
        "            json_str=decode_utf8(pw.this.data),\n",
        "            story_id=extract_id_from_path(pw.this._metadata[\"path\"])\n",
        "        )\n",
        "\n",
        "        # STAGE C: Parse JSON content\n",
        "        backstories_parsed = backstories_table.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            meta=parse_json(pw.this.json_str)\n",
        "        ).select(\n",
        "            story_id=pw.this.story_id,\n",
        "            character_name=pw.this.meta[\"character_name\"]\n",
        "        )\n",
        "\n",
        "        # STAGE D: Join Novels with Backstories\n",
        "        joined_data = novels_table.join(\n",
        "            backstories_parsed,\n",
        "            pw.left.story_id == pw.right.story_id\n",
        "        ).select(\n",
        "            pw.left.story_id,\n",
        "            pw.left.text,\n",
        "            pw.right.character_name\n",
        "        )\n",
        "\n",
        "        # STAGE F: Apply Chunker\n",
        "        result_table = joined_data.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            chunk_json=apply_chunker(pw.this.story_id, pw.this.text, pw.this.character_name)\n",
        "        )\n",
        "\n",
        "        return result_table\n",
        "\n",
        "    def run(self):\n",
        "        pipeline = self.build_pipeline()\n",
        "        pw.debug.compute_and_print(pipeline)\n",
        "\n",
        "print(\"‚úÖ T9 Fixed: VeritasDAG updated with bracket access for metadata.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvRjDRgcaKKU",
        "outputId": "e5d3f8fa-0561-4777-96cf-95281a1c5fe7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T9 Fixed: VeritasDAG updated with bracket access for metadata.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VERIFY TASK T9 ---\n",
        "print(\"Running Pathway Pipeline...\")\n",
        "dag = VeritasDAG()\n",
        "dag.run()\n",
        "\n",
        "print(\"\\n---------------------------------------------------\")\n",
        "print(\"‚úÖ CHECKLIST:\")\n",
        "print(\"1. Look at the table above.\")\n",
        "print(\"2. Do you see 'novel_001', 'novel_002', 'novel_003' in the story_id column?\")\n",
        "print(\"3. Does 'chunk_json' have text like '[{\\\"chunk_id\\\": ...'?\")\n",
        "print(\"If YES, you have successfully finished Day 1 Engineering.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ_62DCgaQKD",
        "outputId": "754d066b-5f2f-472c-d4f3-cd40df44c029"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(./data/test_novels/): Closing the data source\n",
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(./data/backstories/): Closing the data source\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Pathway Pipeline...\n",
            "            | story_id   | chunk_json\n",
            "^D1GVM6Z... | novel_001\" | [{\"error\": \"'Json' object has no attribute 'lower'\"}]\n",
            "^E4Z6ZV7... | novel_002\" | [{\"error\": \"'Json' object has no attribute 'lower'\"}]\n",
            "^6HZ6Q0G... | novel_003\" | [{\"error\": \"'Json' object has no attribute 'lower'\"}]\n",
            "\n",
            "---------------------------------------------------\n",
            "‚úÖ CHECKLIST:\n",
            "1. Look at the table above.\n",
            "2. Do you see 'novel_001', 'novel_002', 'novel_003' in the story_id column?\n",
            "3. Does 'chunk_json' have text like '[{\"chunk_id\": ...'?\n",
            "If YES, you have successfully finished Day 1 Engineering.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK T9 FINAL FIX (PROTOCOL 4) ---\n",
        "import pathway as pw\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- UDFs (With Type Safety Fixes) ---\n",
        "\n",
        "@pw.udf\n",
        "def decode_utf8(data: bytes) -> str:\n",
        "    try:\n",
        "        return data.decode('utf-8')\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "@pw.udf\n",
        "def extract_id_from_path(path_val) -> str:\n",
        "    full_path = str(path_val)\n",
        "    filename = os.path.basename(full_path)\n",
        "    return filename.replace(\".txt\", \"\").replace(\".json\", \"\")\n",
        "\n",
        "@pw.udf\n",
        "def parse_json(json_str: str) -> dict:\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "@pw.udf\n",
        "def apply_chunker(story_id: str, text: str, character: str) -> str:\n",
        "    # --- CRITICAL FIX ---\n",
        "    # Convert inputs to native Python strings to avoid \"Json object\" errors\n",
        "    s_id = str(story_id)\n",
        "    txt = str(text)\n",
        "\n",
        "    # Handle the character name carefully\n",
        "    # If it came in as a JSON string (e.g. \"Elena\"), stripping quotes helps\n",
        "    char = str(character).strip('\"')\n",
        "\n",
        "    if not txt or not char:\n",
        "        return json.dumps([])\n",
        "\n",
        "    try:\n",
        "        # Re-initialize chunker here\n",
        "        c = HierarchicalChunker()\n",
        "        chunk_objs = c.chunk_novel(s_id, txt, char)\n",
        "        return json.dumps([vars(ch) for ch in chunk_objs])\n",
        "    except Exception as e:\n",
        "        return json.dumps([{\"error\": f\"Chunker Failed: {str(e)}\"}])\n",
        "\n",
        "\n",
        "# --- THE PIPELINE CLASS ---\n",
        "class VeritasDAG:\n",
        "    def build_pipeline(self):\n",
        "        # 1. Read Novels\n",
        "        novels = pw.io.fs.read(\n",
        "            \"./data/test_novels/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "        novels_table = novels.select(\n",
        "            text=decode_utf8(pw.this.data),\n",
        "            story_id=extract_id_from_path(pw.this._metadata[\"path\"])\n",
        "        )\n",
        "\n",
        "        # 2. Read Backstories\n",
        "        backstories = pw.io.fs.read(\n",
        "            \"./data/backstories/\",\n",
        "            format=\"binary\",\n",
        "            mode=\"static\",\n",
        "            with_metadata=True\n",
        "        )\n",
        "        backstories_table = backstories.select(\n",
        "            json_str=decode_utf8(pw.this.data),\n",
        "            story_id=extract_id_from_path(pw.this._metadata[\"path\"])\n",
        "        )\n",
        "\n",
        "        # 3. Parse JSON\n",
        "        backstories_parsed = backstories_table.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            meta=parse_json(pw.this.json_str)\n",
        "        ).select(\n",
        "            story_id=pw.this.story_id,\n",
        "            character_name=pw.this.meta[\"character_name\"]\n",
        "        )\n",
        "\n",
        "        # 4. Join\n",
        "        joined_data = novels_table.join(\n",
        "            backstories_parsed,\n",
        "            pw.left.story_id == pw.right.story_id\n",
        "        ).select(\n",
        "            pw.left.story_id,\n",
        "            pw.left.text,\n",
        "            pw.right.character_name\n",
        "        )\n",
        "\n",
        "        # 5. Apply Chunker (with fix)\n",
        "        result_table = joined_data.select(\n",
        "            story_id=pw.this.story_id,\n",
        "            chunk_json=apply_chunker(pw.this.story_id, pw.this.text, pw.this.character_name)\n",
        "        )\n",
        "\n",
        "        return result_table\n",
        "\n",
        "    def run(self):\n",
        "        pipeline = self.build_pipeline()\n",
        "        pw.debug.compute_and_print(pipeline)\n",
        "\n",
        "print(\"‚úÖ T9 Final Protocol: Type conversion added to prevent Json Object errors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjaOS2SOahD7",
        "outputId": "91231f31-e6d8-427b-a789-18ae5cc89436"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T9 Final Protocol: Type conversion added to prevent Json Object errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Final Pipeline Check...\")\n",
        "dag = VeritasDAG()\n",
        "dag.run()\n",
        "\n",
        "print(\"\\n---------------------------------------------------\")\n",
        "print(\"‚úÖ CHECKLIST:\")\n",
        "print(\"1. Look at the 'chunk_json' column.\")\n",
        "print(\"2. It should start with '[{'chunk_id': ... 'text': ...\")\n",
        "print(\"3. If you see REAL DATA, then Member A's work is DONE!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUgZTVl5ajQM",
        "outputId": "1302ac8b-dff1-41c5-8370-fa3de5b4f25d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(./data/test_novels/): Closing the data source\n",
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(./data/backstories/): Closing the data source\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Final Pipeline Check...\n",
            "            | story_id   | chunk_json\n",
            "^D1GVM6Z... | novel_001\" | [{\"chunk_id\": \"novel_001\\\"_ch1\", \"story_id\": \"novel_001\\\"\", \"level\": 1, \"text\": \"Chapter 1: The Morning Routine\\nElena woke up to the sound of rain tapping against her apartment window in Madrid. She stretched her arms. The small studio was quiet.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_001\\\"_ch1_sc1\", \"story_id\": \"novel_001\\\"\", \"level\": 2, \"text\": \"Chapter 1: The Morning Routine\\nElena woke up to the sound of rain tapping against her apartment window in Madrid. She stretched her arms. The small studio was quiet.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch1\"}, {\"chunk_id\": \"novel_001\\\"_ch1_sc1_s1\", \"story_id\": \"novel_001\\\"\", \"level\": 3, \"text\": \"Chapter 1: The Morning Routine\\nElena woke up to the sound of rain tapping against her apartment window in Madrid.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch1_sc1\"}, {\"chunk_id\": \"novel_001\\\"_ch2\", \"story_id\": \"novel_001\\\"\", \"level\": 1, \"text\": \"Chapter 2: Work and Life\\nHer job at the library was demanding but rewarding. She spent the morning organizing the new history section. \\\"Elena, can you help with the archive?\\\" her manager asked.\", \"chapter_num\": 2, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_001\\\"_ch2_sc1\", \"story_id\": \"novel_001\\\"\", \"level\": 2, \"text\": \"Chapter 2: Work and Life\\nHer job at the library was demanding but rewarding. She spent the morning organizing the new history section. \\\"Elena, can you help with the archive?\\\" her manager asked.\", \"chapter_num\": 2, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch2\"}, {\"chunk_id\": \"novel_001\\\"_ch2_sc1_s3\", \"story_id\": \"novel_001\\\"\", \"level\": 3, \"text\": \"\\\"Elena, can you help with the archive?\\\"\", \"chapter_num\": 2, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch2_sc1\"}, {\"chunk_id\": \"novel_001\\\"_ch3\", \"story_id\": \"novel_001\\\"\", \"level\": 1, \"text\": \"Chapter 3: Memories\\nWalking home, she passed the old convent school. It brought back fleeting memories of her childhood. She preferred focusing on the independence she had built.\", \"chapter_num\": 3, \"characters_mentioned\": [], \"has_target_character\": false, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_001\\\"_ch3_sc1\", \"story_id\": \"novel_001\\\"\", \"level\": 2, \"text\": \"Chapter 3: Memories\\nWalking home, she passed the old convent school. It brought back fleeting memories of her childhood. She preferred focusing on the independence she had built.\", \"chapter_num\": 3, \"characters_mentioned\": [], \"has_target_character\": false, \"parent_chunk_id\": \"novel_001\\\"_ch3\"}, {\"chunk_id\": \"novel_001\\\"_ch4\", \"story_id\": \"novel_001\\\"\", \"level\": 1, \"text\": \"Chapter 4: The Phone Call\\nThat evening, Elena met her friend Sofia. \\\"I know what you mean,\\\" Elena said casually. \\\"I actually called my father yesterday to ask for some money, and he wouldn't stop lecturing me.\\\" Sofia looked at her, confused.\", \"chapter_num\": 4, \"characters_mentioned\": [\"Sofia\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_001\\\"_ch4_sc1\", \"story_id\": \"novel_001\\\"\", \"level\": 2, \"text\": \"Chapter 4: The Phone Call\\nThat evening, Elena met her friend Sofia. \\\"I know what you mean,\\\" Elena said casually. \\\"I actually called my father yesterday to ask for some money, and he wouldn't stop lecturing me.\\\" Sofia looked at her, confused.\", \"chapter_num\": 4, \"characters_mentioned\": [\"Sofia\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch4\"}, {\"chunk_id\": \"novel_001\\\"_ch4_sc1_s1\", \"story_id\": \"novel_001\\\"\", \"level\": 3, \"text\": \"Chapter 4: The Phone Call\\nThat evening, Elena met her friend Sofia.\", \"chapter_num\": 4, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch4_sc1\"}, {\"chunk_id\": \"novel_001\\\"_ch4_sc1_s2\", \"story_id\": \"novel_001\\\"\", \"level\": 3, \"text\": \"\\\"I know what you mean,\\\" Elena said casually.\", \"chapter_num\": 4, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch4_sc1\"}, {\"chunk_id\": \"novel_001\\\"_ch5\", \"story_id\": \"novel_001\\\"\", \"level\": 1, \"text\": \"Chapter 5: Evening Calm\\nBack home, Elena read a book until her eyes grew heavy. She drifted into a peaceful sleep.\", \"chapter_num\": 5, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_001\\\"_ch5_sc1\", \"story_id\": \"novel_001\\\"\", \"level\": 2, \"text\": \"Chapter 5: Evening Calm\\nBack home, Elena read a book until her eyes grew heavy. She drifted into a peaceful sleep.\", \"chapter_num\": 5, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch5\"}, {\"chunk_id\": \"novel_001\\\"_ch5_sc1_s1\", \"story_id\": \"novel_001\\\"\", \"level\": 3, \"text\": \"Chapter 5: Evening Calm\\nBack home, Elena read a book until her eyes grew heavy.\", \"chapter_num\": 5, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_001\\\"_ch5_sc1\"}]\n",
            "^E4Z6ZV7... | novel_002\" | [{\"chunk_id\": \"novel_002\\\"_ch1\", \"story_id\": \"novel_002\\\"\", \"level\": 1, \"text\": \"Chapter 1: The Move\\nJames looked at the boxes stacked in his living room. At age 25, he was finally moving out of his parents' house in Seattle. He had lived here his entire life, never venturing further than the state border.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_002\\\"_ch1_sc1\", \"story_id\": \"novel_002\\\"\", \"level\": 2, \"text\": \"Chapter 1: The Move\\nJames looked at the boxes stacked in his living room. At age 25, he was finally moving out of his parents' house in Seattle. He had lived here his entire life, never venturing further than the state border.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_002\\\"_ch1\"}, {\"chunk_id\": \"novel_002\\\"_ch1_sc1_s1\", \"story_id\": \"novel_002\\\"\", \"level\": 3, \"text\": \"Chapter 1: The Move\\nJames looked at the boxes stacked in his living room.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_002\\\"_ch1_sc1\"}, {\"chunk_id\": \"novel_002\\\"_ch2\", \"story_id\": \"novel_002\\\"\", \"level\": 1, \"text\": \"Chapter 2: The New Job\\nHis new job in Portland was exciting. He spent the first few weeks learning the ropes. He missed his mom's cooking but enjoyed the freedom.\", \"chapter_num\": 2, \"characters_mentioned\": [], \"has_target_character\": false, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_002\\\"_ch2_sc1\", \"story_id\": \"novel_002\\\"\", \"level\": 2, \"text\": \"Chapter 2: The New Job\\nHis new job in Portland was exciting. He spent the first few weeks learning the ropes. He missed his mom's cooking but enjoyed the freedom.\", \"chapter_num\": 2, \"characters_mentioned\": [], \"has_target_character\": false, \"parent_chunk_id\": \"novel_002\\\"_ch2\"}, {\"chunk_id\": \"novel_002\\\"_ch3\", \"story_id\": \"novel_002\\\"\", \"level\": 1, \"text\": \"Chapter 3: Old Photos\\nOne evening, he was showing his girlfriend, Maya, some old photo albums. \\\"Look at this one,\\\" James said, pointing to a picture of a boy eating a croissant. \\\"That was me in Paris when I was ten. The Eiffel Tower was huge!\\\" Maya smiled, not realizing the inconsistency.\", \"chapter_num\": 3, \"characters_mentioned\": [\"James\", \"Maya\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_002\\\"_ch3_sc1\", \"story_id\": \"novel_002\\\"\", \"level\": 2, \"text\": \"Chapter 3: Old Photos\\nOne evening, he was showing his girlfriend, Maya, some old photo albums. \\\"Look at this one,\\\" James said, pointing to a picture of a boy eating a croissant. \\\"That was me in Paris when I was ten. The Eiffel Tower was huge!\\\" Maya smiled, not realizing the inconsistency.\", \"chapter_num\": 3, \"characters_mentioned\": [\"James\", \"Maya\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_002\\\"_ch3\"}, {\"chunk_id\": \"novel_002\\\"_ch3_sc1_s2\", \"story_id\": \"novel_002\\\"\", \"level\": 3, \"text\": \"\\\"Look at this one,\\\" James said, pointing to a picture of a boy eating a croissant.\", \"chapter_num\": 3, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_002\\\"_ch3_sc1\"}, {\"chunk_id\": \"novel_002\\\"_ch4\", \"story_id\": \"novel_002\\\"\", \"level\": 1, \"text\": \"Chapter 4: The Routine\\nMonths passed. James settled into a routine of work, gym, and sleep.\", \"chapter_num\": 4, \"characters_mentioned\": [\"James\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_002\\\"_ch4_sc1\", \"story_id\": \"novel_002\\\"\", \"level\": 2, \"text\": \"Chapter 4: The Routine\\nMonths passed. James settled into a routine of work, gym, and sleep.\", \"chapter_num\": 4, \"characters_mentioned\": [\"James\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_002\\\"_ch4\"}, {\"chunk_id\": \"novel_002\\\"_ch4_sc1_s2\", \"story_id\": \"novel_002\\\"\", \"level\": 3, \"text\": \"James settled into a routine of work, gym, and sleep.\", \"chapter_num\": 4, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_002\\\"_ch4_sc1\"}, {\"chunk_id\": \"novel_002\\\"_ch5\", \"story_id\": \"novel_002\\\"\", \"level\": 1, \"text\": \"Chapter 5: Reflection\\nHe felt he had grown up. The small town boy was now a city man.\", \"chapter_num\": 5, \"characters_mentioned\": [], \"has_target_character\": false, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_002\\\"_ch5_sc1\", \"story_id\": \"novel_002\\\"\", \"level\": 2, \"text\": \"Chapter 5: Reflection\\nHe felt he had grown up. The small town boy was now a city man.\", \"chapter_num\": 5, \"characters_mentioned\": [], \"has_target_character\": false, \"parent_chunk_id\": \"novel_002\\\"_ch5\"}]\n",
            "^6HZ6Q0G... | novel_003\" | [{\"chunk_id\": \"novel_003\\\"_ch1\", \"story_id\": \"novel_003\\\"\", \"level\": 1, \"text\": \"Chapter 1: The Detective\\nSarah polished her badge. She had been a detective for ten years in London. She was known for her sharp eye and dedication.\", \"chapter_num\": 1, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_003\\\"_ch1_sc1\", \"story_id\": \"novel_003\\\"\", \"level\": 2, \"text\": \"Chapter 1: The Detective\\nSarah polished her badge. She had been a detective for ten years in London. She was known for her sharp eye and dedication.\", \"chapter_num\": 1, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch1\"}, {\"chunk_id\": \"novel_003\\\"_ch1_sc1_s1\", \"story_id\": \"novel_003\\\"\", \"level\": 3, \"text\": \"Chapter 1: The Detective\\nSarah polished her badge.\", \"chapter_num\": 1, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch1_sc1\"}, {\"chunk_id\": \"novel_003\\\"_ch2\", \"story_id\": \"novel_003\\\"\", \"level\": 1, \"text\": \"Chapter 2: The Case\\nA new case landed on her desk. A missing painting. Sarah visited the museum immediately. She interviewed the guard, who looked nervous.\", \"chapter_num\": 2, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_003\\\"_ch2_sc1\", \"story_id\": \"novel_003\\\"\", \"level\": 2, \"text\": \"Chapter 2: The Case\\nA new case landed on her desk. A missing painting. Sarah visited the museum immediately. She interviewed the guard, who looked nervous.\", \"chapter_num\": 2, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch2\"}, {\"chunk_id\": \"novel_003\\\"_ch2_sc1_s3\", \"story_id\": \"novel_003\\\"\", \"level\": 3, \"text\": \"Sarah visited the museum immediately.\", \"chapter_num\": 2, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch2_sc1\"}, {\"chunk_id\": \"novel_003\\\"_ch3\", \"story_id\": \"novel_003\\\"\", \"level\": 1, \"text\": \"Chapter 3: The Clue\\nShe found a glove near the exit. It matched the description of the suspect. Sarah called her partner. \\\"We have a lead,\\\" she said efficiently.\", \"chapter_num\": 3, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_003\\\"_ch3_sc1\", \"story_id\": \"novel_003\\\"\", \"level\": 2, \"text\": \"Chapter 3: The Clue\\nShe found a glove near the exit. It matched the description of the suspect. Sarah called her partner. \\\"We have a lead,\\\" she said efficiently.\", \"chapter_num\": 3, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch3\"}, {\"chunk_id\": \"novel_003\\\"_ch3_sc1_s3\", \"story_id\": \"novel_003\\\"\", \"level\": 3, \"text\": \"Sarah called her partner.\", \"chapter_num\": 3, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch3_sc1\"}, {\"chunk_id\": \"novel_003\\\"_ch4\", \"story_id\": \"novel_003\\\"\", \"level\": 1, \"text\": \"Chapter 4: The Chase\\nThey tracked the suspect to a warehouse. Sarah remembered her training at the academy. She flanked the left side while her partner took the right.\", \"chapter_num\": 4, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_003\\\"_ch4_sc1\", \"story_id\": \"novel_003\\\"\", \"level\": 2, \"text\": \"Chapter 4: The Chase\\nThey tracked the suspect to a warehouse. Sarah remembered her training at the academy. She flanked the left side while her partner took the right.\", \"chapter_num\": 4, \"characters_mentioned\": [\"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch4\"}, {\"chunk_id\": \"novel_003\\\"_ch4_sc1_s2\", \"story_id\": \"novel_003\\\"\", \"level\": 3, \"text\": \"Sarah remembered her training at the academy.\", \"chapter_num\": 4, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch4_sc1\"}, {\"chunk_id\": \"novel_003\\\"_ch5\", \"story_id\": \"novel_003\\\"\", \"level\": 1, \"text\": \"Chapter 5: Justice\\nThey caught the thief. The painting was returned. Sarah went home to her cat, Mittens, satisfied with a job well done.\", \"chapter_num\": 5, \"characters_mentioned\": [\"Mittens\", \"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": null}, {\"chunk_id\": \"novel_003\\\"_ch5_sc1\", \"story_id\": \"novel_003\\\"\", \"level\": 2, \"text\": \"Chapter 5: Justice\\nThey caught the thief. The painting was returned. Sarah went home to her cat, Mittens, satisfied with a job well done.\", \"chapter_num\": 5, \"characters_mentioned\": [\"Mittens\", \"Sarah\"], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch5\"}, {\"chunk_id\": \"novel_003\\\"_ch5_sc1_s3\", \"story_id\": \"novel_003\\\"\", \"level\": 3, \"text\": \"Sarah went home to her cat, Mittens, satisfied with a job well done.\", \"chapter_num\": 5, \"characters_mentioned\": [], \"has_target_character\": true, \"parent_chunk_id\": \"novel_003\\\"_ch5_sc1\"}]\n",
            "\n",
            "---------------------------------------------------\n",
            "‚úÖ CHECKLIST:\n",
            "1. Look at the 'chunk_json' column.\n",
            "2. It should start with '[{'chunk_id': ... 'text': ...\n",
            "3. If you see REAL DATA, then Member A's work is DONE!\n"
          ]
        }
      ]
    }
  ]
}